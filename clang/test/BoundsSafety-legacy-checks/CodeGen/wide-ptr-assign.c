// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --replace-value-regex "!annotation ![0-9]+" "!tbaa ![0-9]+" "!tbaa\.struct ![0-9]+" "!nosanitize ![0-9]+" "!srcloc ![0-9]+" --prefix-filecheck-ir-name TMP_
// RUN: %clang_cc1 -O0  -fbounds-safety -emit-llvm -triple arm64 %s -o - | FileCheck %s
// RUN: %clang_cc1 -O0  -fbounds-safety -x objective-c -fbounds-attributes-objc-experimental -emit-llvm -triple arm64 %s -o - | FileCheck %s

#include <ptrcheck.h>

// CHECK-LABEL: @wide_array_subscript(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[BUF:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    store [2 x i64] [[BUF_COERCE:%.*]], ptr [[BUF]], align 8
// CHECK-NEXT:    store i32 [[I:%.*]], ptr [[I_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[BUF]], i64 16, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I_ADDR]], align 4
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr %"__bounds_safety::wide_ptr.indexable.0", ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = icmp ult ptr [[TMP4]], [[WIDE_PTR_UB5]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP5]], label [[CONT:%.*]], label [[TRAP:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4:[0-9]+]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont:
// CHECK-NEXT:    [[TMP6:%.*]] = icmp uge ptr [[TMP4]], [[WIDE_PTR_LB]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP6]], label [[CONT7:%.*]], label [[TRAP6:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap6:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont7:
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[TMP4]], i8 0, i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void wide_array_subscript(int *__indexable *__indexable buf, int i) {
  buf[i] = 0;
}

// CHECK-LABEL: @wide_array_subscript_load(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[BUF:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    store [2 x i64] [[BUF_COERCE:%.*]], ptr [[BUF]], align 8
// CHECK-NEXT:    store i32 [[I:%.*]], ptr [[I_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[BUF]], i64 16, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP0]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = load i32, ptr [[I_ADDR]], align 4
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP3]] to i64
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr %"__bounds_safety::wide_ptr.indexable.0", ptr [[WIDE_PTR_PTR3]], i64 [[IDXPROM]]
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = icmp ult ptr [[TMP4]], [[WIDE_PTR_UB5]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP5]], label [[CONT:%.*]], label [[TRAP:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont:
// CHECK-NEXT:    [[TMP6:%.*]] = icmp uge ptr [[TMP4]], [[WIDE_PTR_LB]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP6]], label [[CONT7:%.*]], label [[TRAP6:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap6:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont7:
// CHECK-NEXT:    ret void
//
void wide_array_subscript_load(int *__indexable *__indexable buf, int i) {
  (void)buf[i];
}

// CHECK-LABEL: @wide_array_subscript_addr(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[BUF:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[AGG_TMP_ENSURED:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    store [2 x i64] [[BUF_COERCE:%.*]], ptr [[BUF]], align 8
// CHECK-NEXT:    store i32 [[I:%.*]], ptr [[I_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[I_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[BUF]], i64 16, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// CHECK-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// CHECK-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr %"__bounds_safety::wide_ptr.indexable.0", ptr [[TMP5]], i64 [[IDXPROM]]
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TMP_ENSURED]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TMP_ENSURED]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// CHECK-NEXT:    [[TMP11:%.*]] = load ptr, ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TMP_ENSURED]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP11]], ptr [[TMP12]], align 8
// CHECK-NEXT:    ret void
//
void wide_array_subscript_addr(int *__indexable *__indexable buf, int i) {
  (void)&buf[i];
}

// CHECK-LABEL: @wide_deref(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[BUF:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    [[I_ADDR:%.*]] = alloca i32, align 4
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP1:%.*]] = alloca %"__bounds_safety::wide_ptr.indexable", align 8
// CHECK-NEXT:    store [2 x i64] [[BUF_COERCE:%.*]], ptr [[BUF]], align 8
// CHECK-NEXT:    store i32 [[I:%.*]], ptr [[I_ADDR]], align 4
// CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[I_ADDR]], align 4
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP1]], ptr align 8 [[BUF]], i64 16, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.indexable", ptr [[AGG_TEMP1]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP1]], align 8
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[WIDE_PTR_UB]], ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[WIDE_PTR_PTR]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// CHECK-NEXT:    [[TMP5:%.*]] = load ptr, ptr [[TMP4]], align 8
// CHECK-NEXT:    [[IDXPROM:%.*]] = sext i32 [[TMP0]] to i64
// CHECK-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr %"__bounds_safety::wide_ptr.indexable.0", ptr [[TMP5]], i64 [[IDXPROM]]
// CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP6]], align 8
// CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[TMP7]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP9]], align 8
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// CHECK-NEXT:    [[TMP11:%.*]] = load ptr, ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP11]], ptr [[TMP12]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR3:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR2]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR4:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB5:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    [[TMP13:%.*]] = icmp ult ptr [[WIDE_PTR_PTR3]], [[WIDE_PTR_UB5]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP13]], label [[CONT:%.*]], label [[TRAP:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont:
// CHECK-NEXT:    [[TMP14:%.*]] = icmp uge ptr [[WIDE_PTR_PTR3]], [[WIDE_PTR_LB]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP14]], label [[CONT7:%.*]], label [[TRAP6:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap6:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont7:
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[WIDE_PTR_PTR3]], i8 0, i64 16, i1 false)
// CHECK-NEXT:    ret void
//
void wide_deref(int *__indexable *__indexable buf, int i) {
  *(buf + i) = 0;
}

struct wide_member_t {
  int *__bidi_indexable ptr;
};
// CHECK-LABEL: @wide_member_assign(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[W_INDIRECT_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable.1", align 8
// CHECK-NEXT:    store ptr [[W:%.*]], ptr [[W_INDIRECT_ADDR]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP]], ptr align 8 [[W]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable.1", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = getelementptr [[STRUCT_WIDE_MEMBER_T:%.*]], ptr [[WIDE_PTR_PTR]], i64 1
// CHECK-NEXT:    [[TMP1:%.*]] = icmp ule ptr [[TMP0]], [[WIDE_PTR_UB]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP1]], label [[CONT:%.*]], label [[TRAP:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont:
// CHECK-NEXT:    [[TMP2:%.*]] = icmp ule ptr [[WIDE_PTR_LB]], [[WIDE_PTR_PTR]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP2]], label [[CONT2:%.*]], label [[TRAP1:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap1:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable, {{!annotation ![0-9]+}}
// CHECK:       cont2:
// CHECK-NEXT:    [[PTR:%.*]] = getelementptr inbounds [[STRUCT_WIDE_MEMBER_T]], ptr [[WIDE_PTR_PTR]], i32 0, i32 0
// CHECK-NEXT:    call void @llvm.memset.p0.i64(ptr align 8 [[PTR]], i8 0, i64 24, i1 false)
// CHECK-NEXT:    ret void
//
void wide_member_assign(struct wide_member_t *__bidi_indexable w) {
  w->ptr = 0;
}
